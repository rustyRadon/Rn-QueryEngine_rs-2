1. Memory Mapping (Zero-Copy I/O)
    Instead of File::open and BufReader, i am using use mmap.
    The Concept: telling the OS, "Take this 4GB file and map it into my app's memory addresses."
    The Result: You don't "read" the file anymore. You just treat it like a giant slice: &[i32]. When you access an index, the OS hardware (the MMU) fetches that specific page from the disk instantly.
    Why it's faster: Zero copying. The data goes from the disk controller straight to the CPU cache.

2. Parallel Vectorized Execution
    In Repo 1, the CPU was likely at 10-15% usage because it was only using one core.
    The Concept:  i'll break our 1,000,000 rows into "Chunks" (e.g., 64,000 rows each).
    The Implementation: Using a library called Rayon, i'll process these chunks across all CPU cores (4, 8, or 16 cores) simultaneously.
    The Filter: Instead of a FilterWorker that pulls one batch at a time, create a Parallel Scan that crunches the entire file in parallel.

3. Bit-Masks instead of Booleans
    In Repo 1, filter created a Vec<bool>. In Rust, a bool is 8 bits (1 byte). If you have 1,000,000 rows, that’s 1MB of RAM just for "Yes/No" answers.
    The Improvement:  use Bit-Packing.
    The Result: store 8 "Yes/No" answers in a single u8. This makes the selection mask 8 times smaller.
    The Speed: The CPU can "AND" or "OR" 64 rows oOnce you realize you can treat a file like an array, you'll never want to use Read::read() again.f filter logic in a single clock cycle using bitwise operations.  


Repo 1, the flow was: Disk -> OS Buffer -> Rust Buffer -> Vec<i32> -> Filter -> Output
Repo 2, the flow will be: Disk -> (Mapped Memory) -> CPU Cache -> SIMD Filter -> Output

realize you can treat a file like an array, never to use Read::read() again.

dependencies
# The gold standard for memory mapping files
memmap2 = "0.9"
# High-performance parallelism (for the multi-core kernels)
rayon = "1.8"
# Crucial for zero-copy: lets us safely treat byte slices as i32 slices
bytemuck = { version = "1.14", features = ["derive"] }
# Helps ensure our data is aligned with CPU cache lines
aligned-vec = "0.5"

//////////////----------------///////////////
        idea behind the architecture
//////////////----------------///////////////
a p_layer (Physical Layer) creates a dedicated owner for the memory.
The rest of the engine (the v_table) can then safely borrow that memory. This is the only way to do Zero-Copy without getting lost. hmm

util/bits.rs allows the passing around of Bitmasks.You filter Age $\rightarrow$ you get a Bitmask.
pass that Bitmask to the Salary filter $\rightarrow$  get a smaller Bitmask.
You never actually read the Salary data from the disk until you have the final mask. This is why this architecture is 10x–100x faster than a standard row-based engine.

Kernel Testing
putting the filtering logic in kernel/ bassically means writing pure mathematical functions.
You can test your filter_kernel with a simple array of numbers without even touching a file.

The Task: Build a Bitset Wrapper
Your goal is to create a struct that acts like a very fast array of bits.


//////////////----------------///////////////
                   utils
//////////////----------------///////////////
1. The Structure
    Create a struct named BitMask.
    Inside, it should have one field (let's call it bits) which is a Vec<u64>.
    Why u64? Because CPUs are optimized to process 64 bits at a time.

2. The Logic: 
    wrote a constructor pub fn new(size: usize) -> Self.
    Calculate how many u64 elements you need to hold size bits.
    It’s (size + 63) / 64. Initialize the vector with zeros.

3. The Logic: set 
    Wrote a function pub fn set(&mut self, index: usize).
    This needs to find which u64 in the vector the index belongs to (index / 64).
    Then, it needs to find which specific bit inside that u64 to flip (index % 64).
    Used the bitwise OR operator (|) and the Left Shift operator (<<) to turn that specific bit to 1.

4. The Logic: get 
    Write a function pub fn get(&self, index: usize) -> bool.
    Similar to set, i found the correct u64 and the bit position.
    Used the bitwise AND operator (&) to check if that bit is 1. Return true if it is, false otherwise.



//////////////----------------///////////////
                   kernel
//////////////----------------/////////////// 

function :
    checks a large list of numbers in parallel
     packs each YES/NO result into bits
     returns a fast, memory-efficient BitMask showing which values passed the rule.